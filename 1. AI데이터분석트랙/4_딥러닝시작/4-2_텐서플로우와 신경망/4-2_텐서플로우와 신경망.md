### 4-2. 텐서플로우와 신경망



**Q. 다음 중 딥러닝 모델과 딥러닝 모델의 학습 방법에 대한 설명으로 옳지 않은 것을 고르세요.**

1. 히든층이 많아질 경우, 깊은 신경망이라는 의미의 Deep Learning 단어를 사용한다..(O)
2. 딥러닝 모델 학습과정에서는 예측값과 실제값 간의 오차값을 최소화하기 위한 알고리즘을 적용한다.(O)
3. 경사 하강법(Gradient descent)을 사용하여 최적화를 진행한다.(O)
4. 입력값을 바탕으로 출력값을 계산하는 과정을 역전파라고 부른다.(X)

```
입력값을 바탕으로 출력값을 계산하는 과정은 순전파(Forward propagation)라고 부릅니다.
반대로, 순전파의 반대 방향으로 이루어지는 과정을 역전파(Backpropogation)이라고 부릅니다.

딥러닝 모델의 학습 방법은 다음과 같습니다.

①학습용 feature 데이터를 입력하여 예측값 구하기(순전파)
②예측값과 실제값 사이의 오차 구하기(Loss계산)
③Loss를 줄일 수 있는 가중치 업데이트하(역전파)
④1~3번 반복으로 Loss를 최소로 하는 가중치 얻기
```



**텐서플로우를 활용하여 신경망 구현하기**

1. 데이터 전 처리

> * 텐서플로우를 활용하여 신경망을 구현해보는 과정을 수행해보겠습니다.
> * 여러분은 마케터로서 광고 비용에 따른 수익률을 신경망을 통해서 예측하고자 합니다.
> * 아래와 같이 `FB`, `TV`, `Newspaper` 광고에 대한 비용 대비 `Sales` 데이터가 주어진다면 우선 데이터 전 처리를 수행하여 텐서플로우 딥러닝 모델에 필요한 학습용 데이터를 만들어 봅시다.
>
> ![marketing](.\marketing.png)
>
> * 텐서플로우 신경망 모델의 학습 데이터를 만드는 함수/메서드
>
> > * 텐서플로우 신경망 모델의 학습 데이터는 기존 데이터를 `tf.data.Dataset` 형식으로 변환하여 사용합니다.
> >
> > * pandas의 DataFrame 형태 데이터를 Dataset으로 변환하기 위해서는 아래의 `from_tensor_slices()` 메서드를 사용하여 `ds`에 저장할 수 있습니다.
> >
> >   ```python
> >   ds = tf.data.Dataset.from_tensor_slices((X.values, Y.values))
> >   ```
> >
> > * `X`는 feature 데이터가 저장된 DataFrame이고, `Y`는 label 데이터가 저장된 Series 입니다. 여기서 `X, Y` 데이터는 `X.values, Y.values`를 사용하여 리스트 형태로 입력합니다.
> >
> > * 이후 변환된 Dataset인 `ds`에서 batch를 적용하고 싶다면 아래와 같이 `batch()` 메서드를 사용합니다.
> >
> > ```python
> > ds = ds.shuffle(len(X)).batch(batch_size=5)
> > ```
> >
> > > * `shuffle` 메서드를 사용하여 데이터를 셔플합니다. 인자로는 데이터의 크기를 입력합니다.
> > > * `batch` 메서드를 사용하여 `batch_size`에 batch 크기를 넣게 되면 해당 크기로 batch를 수행하게 됩니다.
> >
> > * 이렇게 처리한 `ds`에서 `take()`메서드를 사용하면 batch로 분리된 데이터를 확인할 수 있습니다.

```python
'''
<목표>
1. pandas DataFrame df에서 Sales 변수는 label 데이터로 Y에 저장하고 나머진 X에 저장합니다.
2. 학습용 데이터 train_X, train_Y를 tf.data.Dataset 형태로 변환합니다.
   ※ from_tensor_slices 함수를 사용하여 변환합니다.
'''

import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

np.random.seed(100)
tf.random.set_seed(100)

# 데이터를 DataFrame 형태로 불러 옵니다.
df = pd.read_csv("data/Advertising.csv")

# DataFrame 데이터 샘플 5개를 출력합니다.
print('원본 데이터 샘플 :')
print(df.head(),'\n')

# 의미없는 변수는 삭제합니다.
df = df.drop(columns=['Unnamed: 0'])

"""
1. Sales 변수는 label 데이터로 Y에 저장하고 나머진 X에 저장합니다.
"""
X = df.drop(columns=['Sales'])
Y = df['Sales']

train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.3)

"""
2. 학습용 데이터를 tf.data.Dataset 형태로 변환합니다.
   from_tensor_slices 함수를 사용하여 변환하고 batch_size는 5로 설정합니다.
"""
train_ds = tf.data.Dataset.from_tensor_slices((train_X.values, train_Y))
train_ds = train_ds.shuffle(len(train_X)).batch(batch_size=5)

# 하나의 batch를 뽑아서 feature와 label로 분리합니다.
[(train_features_batch, label_batch)] = train_ds.take(1)

# batch 데이터를 출력합니다.
print('\nFB, TV, Newspaper batch 데이터:\n',train_features_batch)
print('Sales batch 데이터:',label_batch)
    
'''
원본 데이터 샘플 :
   Unnamed: 0     FB    TV  Newspaper  Sales
0           1  230.1  37.8       69.2   22.1
1           2   44.5  39.3       45.1   10.4
2           3   17.2  45.9       69.3    9.3
3           4  151.5  41.3       58.5   18.5
4           5  180.8  10.8       58.4   12.9 


FB, TV, Newspaper batch 데이터:
 tf.Tensor(
[[296.4  36.3 100.9]
 [228.   37.7  32. ]
 [  5.4  29.9   9.4]
 [ 57.5  32.8  23.5]
 [240.1   7.3   8.7]], shape=(5, 3), dtype=float64)
Sales batch 데이터: tf.Tensor([23.8 21.5  5.3 11.8 13.2], shape=(5,), dtype=float64)
'''
```

2. 모델구현 

> * 이어서 이번 실습에서는 텐서플로우와 **케라스**(**Keras**)를 활용하여 신경망 모델을 구현해보겠습니다.
> * 케라스는 텐서플로우 내의 신경망 모델 설계와 훈련을 위한 API 입니다. 케라스는 연속적으로(Sequential) 레이어(Layer)들을 쌓아가며 모델을 생성하고, 사이킷런과 같이 한 줄의 코드로 간단하게 학습 방법 설정, 학습, 평가를 진행할 수 있습니다.
> * 텐서플로우 신경망 모델의 학습 데이터를 만드는 함수/메서드
>
> > * 모델설정
> >
> > ```python
> > # 연속적으로 층을 쌓아 만드는 Sequential 모델을 위한 함수
> > tf.keras.models.Sequential()
> > ```
> >
> > * Dense 레이어
> >
> > ```python
> > # 신경망 모델의 레이어를 구성하는데 필요한 keras 함수
> > tf.keras.layers.Dense(units)
> > ```
> >
> > > - `units`: 레이어 안의 노드 수
> >
> > * 예를 들어, 5개의 변수에 따른 label 을 예측하는 회귀 분석 신경망을 구현하고 싶다면 아래와 같이 구현할 수 있습니다.
> >
> > ```python
> > tf.keras.models.Sequential([
> >     tf.keras.layers.Dense(10, input_shape=(5,)),
> >     tf.keras.layers.Dense(1)
> >     ])
> > ```
> >
> > > * `input_shape` 인자에는 (입력하는 변수의 개수, )로 입력합니다. 또한 회귀 분석이기에 마지막 레이어의 유닛 수는 1개로 설정합니다.
> >
> > * `input_dim`인자를 사용하면 아래와 같이 표현할 수 있습니다.
> >
> > ```python
> > tf.keras.models.Sequential([
> >     tf.keras.layers.Dense(10, input_dim=5),
> >     tf.keras.layers.Dense(1)
> >     ])
> > ```

```python
'''
<목표>
tf.keras.models.Sequential()을 활용하여 신경망 모델을 생성합니다.
※ 자유롭게 layers를 쌓고 마지막 layers는 노드 수를 1개로 설정합니다.
'''
import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

np.random.seed(100)
tf.random.set_seed(100)

# 데이터를 DataFrame 형태로 불러 옵니다.
df = pd.read_csv("data/Advertising.csv")

# DataFrame 데이터 샘플 5개를 출력합니다.
print('원본 데이터 샘플 :')
print(df.head(),'\n')

# 의미없는 변수는 삭제합니다.
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

# 학습용 테스트용 데이터로 분리합니다.
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.3)

# Dataset 형태로 변환합니다.
train_ds = tf.data.Dataset.from_tensor_slices((train_X.values, train_Y))
train_ds = train_ds.shuffle(len(train_X)).batch(batch_size=5)

"""
1. keras를 활용하여 신경망 모델을 생성합니다.
   자유롭게 레이어를 쌓고 마지막 레이어에는 노드 수를 1개로 설정합니다.
"""
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(10, input_shape=(3,)),
    tf.keras.layers.Dense(1)
    ])

print(model.summary())

'''
원본 데이터 샘플 :
   Unnamed: 0     FB    TV  Newspaper  Sales
0           1  230.1  37.8       69.2   22.1
1           2   44.5  39.3       45.1   10.4
2           3   17.2  45.9       69.3    9.3
3           4  151.5  41.3       58.5   18.5
4           5  180.8  10.8       58.4   12.9 

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 10)                40        
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 11        
=================================================================
Total params: 51
Trainable params: 51
Non-trainable params: 0
_________________________________________________________________
None
'''
```

3. 모델학습

> * 이번 실습에서는 텐서플로우와 **케라스**(**Keras**)를 활용하여 신경망 모델을 학습해보겠습니다.
> * 텐서플로우와 케라스를 이용해 신경망 모델을 학습하기 위한 함수/메서드
>
> > * 학습 방법 설정
> >
> > ```python
> > model.compile(loss='mean_squared_error', optimizer='adam')
> > ```
> >
> > > * `complie()` 메서드는 모델을 어떻게 학습할 지에 대해서 설정합니다. loss는 회귀에서는 일반적으로 MSE인 ‘mean_squared_error’, 분류에서는 ‘sparse_categorical_crossentropy’ 를 주로 사용합니다.
> >
> > * 학습 수행
> >
> > ```python
> > model.fit(X, epochs=100, verbose=2)
> > ```
> >
> > > * `X` 데이터를 에포크를 100번으로 하여 학습합니다. `verbose` 인자는 학습 시, 화면에 출력되는 형태를 설정합니다. (0: 표기 없음, 1: 진행 바, 2: 에포크당 한 줄 출력)

```python
'''
<목표>
Dataset으로 변환된 학습용 데이터를 바탕으로 모델의 학습을 수행합니다.
① compile 메서드를 사용하여 최적화 모델을 설정합니다. loss는 ‘mean_squared_error’, optimizer   는 ‘adam’으로 설정합니다.
② fit 메서드를 사용하여 학습용 데이터를 학습합니다. epochs는 100으로 설정합니다.
'''
import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

np.random.seed(100)
tf.random.set_seed(100)

# 데이터를 DataFrame 형태로 불러 옵니다.
df = pd.read_csv("data/Advertising.csv")

# DataFrame 데이터 샘플 5개를 출력합니다.
print('원본 데이터 샘플 :')
print(df.head(),'\n')

# 의미없는 변수는 삭제합니다.
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

# 학습용 테스트용 데이터로 분리합니다.
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.3)

# Dataset 형태로 변환합니다.
train_ds = tf.data.Dataset.from_tensor_slices((train_X.values, train_Y))
train_ds = train_ds.shuffle(len(train_X)).batch(batch_size=5)


# keras를 활용하여 신경망 모델을 생성합니다.
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(10, input_shape=(3,)),
    tf.keras.layers.Dense(1)
    ])


"""

1. 학습용 데이터를 바탕으로 모델의 학습을 수행합니다.
    
step1. compile 메서드를 사용하여 최적화 모델 설정합니다.
       loss는 mean_squared_error, optimizer는 adam으로 설정합니다.
       
step2. fit 메서드를 사용하여 학습용 데이터를 학습합니다.
       epochs는 100으로 설정합니다.
"""
model.compile(loss='mean_squared_error', optimizer='adam')
history = model.fit(train_ds, epochs=100, verbose=2)

'''
원본 데이터 샘플 :
   Unnamed: 0     FB    TV  Newspaper  Sales
0           1  230.1  37.8       69.2   22.1
1           2   44.5  39.3       45.1   10.4
2           3   17.2  45.9       69.3    9.3
3           4  151.5  41.3       58.5   18.5
4           5  180.8  10.8       58.4   12.9 

Epoch 1/100
28/28 - 0s - loss: 1639.5788
(중략)
Epoch 99/100
28/28 - 0s - loss: 3.7437
Epoch 100/100
28/28 - 0s - loss: 3.9819
'''
```

4. 모델 평가 및 예측

> * 학습된 신경망을 모델을 평가하고 예측해보겠습니다.
> * 텐서플로우를 이용해 신경망 모델을 평가 및 예측을 위한 함수/메서드
>
> > * 평가방법
> >
> > ```python
> > model.evaluate(X, Y)
> > ```
> >
> > > `evaluate()` 메서드는 학습된 모델을 바탕으로 입력한 feature 데이터 `X`와 label `Y`의 loss 값과 metrics 값을 출력합니다. 이번 실습에서는 metrics 를 compile에서 설정하지 않았지만, 분류에서는 일반적으로 `accuracy`를 사용하여 evaluate 사용 시, 2개의 아웃풋을 리턴합니다.
> >
> > * 예측방법
> >
> > ```python
> > model.predict(X)
> > ```
> >
> > > `X` 데이터의 예측 label 값을 출력합니다.

```python
'''
<목표>
1. evaluate 메서드를 사용하여 테스트용 데이터의 loss 값을 계산하고 loss에 저장합니다.
2. predict 메서드를 사용하여 테스트용 데이터의 예측값을 계산하고 predictions에 저장합니다.
'''
import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

np.random.seed(100)
tf.random.set_seed(100)

# 데이터를 DataFrame 형태로 불러 옵니다.
df = pd.read_csv("data/Advertising.csv")

# DataFrame 데이터 샘플 5개를 출력합니다.
print('원본 데이터 샘플 :')
print(df.head(),'\n')

# 의미없는 변수는 삭제합니다.
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

# 학습용 테스트용 데이터로 분리합니다.
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.3)

# Dataset 형태로 변환합니다.
train_ds = tf.data.Dataset.from_tensor_slices((train_X.values, train_Y))
train_ds = train_ds.shuffle(len(train_X)).batch(batch_size=5)

# keras를 활용하여 신경망 모델을 생성합니다.
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(10, input_shape=(3,)),
    tf.keras.layers.Dense(1)
    ])

# 학습용 데이터를 바탕으로 모델의 학습을 수행합니다.
model.compile(loss='mean_squared_error', optimizer='adam')
history = model.fit(train_ds, epochs=100, verbose=2)

"""
1. evaluate 메서드를 사용하여 테스트용 데이터의 loss 값을 계산합니다.
"""
loss = model.evaluate(test_X, test_Y)

"""
2. predict 메서드를 사용하여 테스트용 데이터의 예측값을 계산합니다.
"""
predictions = model.predict(test_X)

# 결과를 출력합니다.
print("테스트 데이터의 Loss 값: ", loss)
for i in range(5):
    print("%d 번째 테스트 데이터의 실제값: %f" % (i, test_Y.iloc[i]))
    print("%d 번째 테스트 데이터의 예측값: %f" % (i, predictions[i][0]))

'''
원본 데이터 샘플 :
   Unnamed: 0     FB    TV  Newspaper  Sales
0           1  230.1  37.8       69.2   22.1
1           2   44.5  39.3       45.1   10.4
2           3   17.2  45.9       69.3    9.3
3           4  151.5  41.3       58.5   18.5
4           5  180.8  10.8       58.4   12.9 

Epoch 1/100
28/28 - 0s - loss: 1639.5788
(중략)
Epoch 100/100
28/28 - 0s - loss: 3.9819
WARNING: Logging before flag parsing goes to stderr.
W1109 09:39:12.282430 140533045176064 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
W1109 09:39:12.309829 140533045176064 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>
테스트 데이터의 Loss 값:  3.6781873226165773
0 번째 테스트 데이터의 실제값: 6.600000
0 번째 테스트 데이터의 예측값: 10.392957
1 번째 테스트 데이터의 실제값: 20.700000
1 번째 테스트 데이터의 예측값: 19.001699
2 번째 테스트 데이터의 실제값: 17.200000
2 번째 테스트 데이터의 예측값: 16.554482
3 번째 테스트 데이터의 실제값: 19.400000
3 번째 테스트 데이터의 예측값: 18.733145
4 번째 테스트 데이터의 실제값: 21.800000
4 번째 테스트 데이터의 예측값: 20.184616
'''
```



**신경망 모델로 분류하기**

> * 이번 실습에서는 Iris 데이터가 주어졌을 때 붓꽃의 종류를 분류하는 신경망 모델을 구현합니다.
> *  Iris 데이터는 아래와 같이 꽃받침 길이, 꽃받침 넓이, 꽃잎 길이, 꽃잎 넓이 네 가지 변수와 세 종류의 붓꽃 클래스로 구성되어 있습니다.
>
> ![iris](.\iris.png)
>
> * 분류를 위한 텐서플로우 신경망 모델 함수/메서드
>
> > * 모델 구현 (5개의 범주를 갖는 label 예시)
> >
> > ```python
> > model = tf.keras.models.Sequential([
> > tf.keras.layers.Dense(10, input_dim=4),
> > tf.keras.layers.Dense(5, activation='softmax')
> > ])
> > ```
> >
> > > 분류 모델에서는 마지막 레이어에 분류 데이터의 label 범주의 개수만큼 노드를 설정합니다. 추가로 `activation` 인자로 ‘softmax’ 를 설정합니다.
> >
> > * 학습 방법
> >
> > ```python
> > model.compile(loss=’sparse_categorical_crossentropy’, optimizer=’adam’, metrics=[‘accuracy’])
> > ```
> >
> > > 분류에서는 일반적으로 `loss`를 ‘sparse_categorical_crossentropy’으로 사용합니다. `metrics` 인자는 에포크마다 계산되는 평가 지표를 의미합니다. 정확도를 의미하는 ‘accuracy’ 를 입력하면 에포크마다 accuracy를 계산하여 출력합니다.

```python
'''
<목표>
keras를 활용하여 신경망 모델을 생성합니다. 3가지 범주를 갖는 label 데이터를 분류하기 위해서 마지막 레이어 노드를 아래와 같이 설정합니다.
노드의 수는 3개
activation은 ‘softmax’로 설정합니다.
'''
import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

np.random.seed(100)
tf.random.set_seed(100)

# sklearn에 저장된 데이터를 불러 옵니다.
X, Y = load_iris(return_X_y = True)

# DataFrame으로 변환
df = pd.DataFrame(X, columns=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'])
df['클래스'] = Y

X = df.drop(columns=['클래스'])
Y = df['클래스']

# 학습용 평가용 데이터로 분리합니다
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)

# Dataset 형태로 변환합니다.
train_ds = tf.data.Dataset.from_tensor_slices((train_X.values, train_Y))
train_ds = train_ds.shuffle(len(train_X)).batch(batch_size=5)

"""
1. keras를 활용하여 신경망 모델을 생성합니다.
   3가지 범주를 갖는 label 데이터를 분류하기 위해서 마지막 레이어 노드를 아래와 같이 설정합니다.
"""
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(10, input_dim=4),
    tf.keras.layers.Dense(3, activation='softmax')
    ])

# 학습용 데이터를 바탕으로 모델의 학습을 수행합니다.
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(train_ds, epochs=100, verbose=2)

# 테스트용 데이터를 바탕으로 학습된 모델을 평가합니다.
loss, acc = model.evaluate(test_X, test_Y)

# 테스트용 데이터의 예측값을 구합니다.
predictions = model.predict(test_X)

# 결과를 출력합니다.
print("테스트 데이터의 Accuracy 값: ", acc)
for i in range(5):
    print("%d 번째 테스트 데이터의 실제값: %d" % (i, test_Y.iloc[i]))
    print("%d 번째 테스트 데이터의 예측값: %d" % (i, np.argmax(predictions[i])))
    
 '''
 (중략)
 0 번째 테스트 데이터의 예측값: 1
1 번째 테스트 데이터의 실제값: 0
1 번째 테스트 데이터의 예측값: 0
2 번째 테스트 데이터의 실제값: 2
2 번째 테스트 데이터의 예측값: 2
3 번째 테스트 데이터의 실제값: 1
3 번째 테스트 데이터의 예측값: 1
4 번째 테스트 데이터의 실제값: 1
4 번째 테스트 데이터의 예측값: 1
 '''
```

