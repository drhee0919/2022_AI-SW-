### 3-1. 지도학습-회귀



**Q. 아래 그래프는 회귀 분석에 대한 예시입니다. 아래 그래프와 회귀 분석에 대한 설명으로 옳지 않은 것을 고르세요.**

![regression](.\regression.png)

1. Y = beta_0 + beta_1 * X의 식을 통해 선형 회귀 분석을 하고 있다.(O)
2. 회귀 분석이란, 입력 데이터가 어떤 클래스에 속하는지 예측하기 위한 알고리즘이다.(X)
3. 각 데이터의 실제값과 모델이 예측하는 값의 차이를 최소한으로 하는 선을 찾는 과정으로 진행된다.(O)
4. 완벽한 예측은 불가능하기에 최대한 잘 근사하는 선을 찾는 것이 목표라고 할 수 있다.(O)

```
회귀 분석이란 데이터를 가장 잘 설명하는 선을 찾아 입력값에 따른 미래 결괏값을 예측하는 알고리즘입니다. 즉, 입력 데이터가 어떤 클래스에 속하는지 알아보기 위해 사용하기엔 적절치 않습니다.
```



**단순선형 회귀 분석하기**

1. 데이터 전처리 

> * 기계학습 라이브러리 [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) 을 사용하면 Loss 함수를 최솟값으로 만드는 *β*0, *β*1 을 쉽게 구할 수 있습니다.
> * 주어진 데이터를 sklearn에서 불러 올 선형 모델에 적용하기 위해서는 전 처리가 필요합니다.
> * 이번 실습에서는 sklearn에서 제공하는 `LinearRegression`을 사용하기 위한 데이터 전 처리를 수행해보겠습니다.
> * LinearRegression 모델의 입력값으로는 Pandas의 DataFrame의 feature (X) 데이터와 Series 형태의 label (Y) 데이터를 입력 받을 수 있습니다.
> * 이때, X, Y의 샘플의 개수는 같아야 합니다.

```python
'''
<목표>
1. X 데이터를 column 명이 X인 DataFrame으로 변환하고 train_X에 저장합니다.
2. 리스트 Y를 Series 형식으로 변환하여 train_Y에 저장합니다.
'''
import pandas as pd

from sklearn.linear_model import LinearRegression
    
X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]
Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]


"""
1. X의 형태를 변환하여 train_X에 저장합니다.
"""
train_X = pd.DataFrame(X, columns=['X']) # X를 column 명이 'X'인 Dataframe으로 변환합니다.

"""
2. Y의 형태를 변환하여 train_Y에 저장합니다.
"""
train_Y = pd.Series(Y) # Y를 Series로 변환합니다.

# 변환된 데이터를 출력합니다.
print('전 처리한 X 데이터: \n {}'.format(train_X))
print('전 처리한 X 데이터 shape: {}\n'.format(train_X.shape))

print('전 처리한 Y 데이터: \n {}'.format(train_Y))
print('전 처리한 Y 데이터 shape: {}'.format(train_Y.shape))
```

2. 학습하기

> * (1.에서) 전 처리한 데이터를 `LinearRegression` 모델에 입력하여 학습을 수행해봅시다.
>
> * `LinearRegression`을 사용하기 위해서는 우선 해당 모델 객체를 불러와 초기화해야 합니다. 
> * 아래 코드는 `lrmodel`에 모델 객체를 초기화 하는 것을 보여줍니다.
>
> ```python
> lrmodel = LinearRegression()
> ```
>
> * 모델 초기화를 수행했다면 전 처리된 데이터를 사용하여 학습을 수행할 수 있습니다. 아래코드와 같이 `fit` 함수에 학습에 필요한 데이터를 입력하여 학습을 수행합니다.
>
> ```python
> lrmodel.fit(train_X, train_Y)
> ```
>
> * `LinearRegression`의 *β*0, *β*1 값을 구하기 위해서는 아래 코드를 사용하여 구할 수 있습니다.
>
> ```python
> beta_0 = lrmodel.intercept_
> beta_1 = lrmodel.coef_[0]
> ```

```python
'''
<목표>
1. sklearn의 LinearRegression() 모델을 lrmodel에 초기화 합니다.
2. fit을 사용하여 train_X, train_Y 데이터를 학습합니다.
'''
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LinearRegression

import elice_utils
eu = elice_utils.EliceUtils()

X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]
Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]

train_X = pd.DataFrame(X, columns=['X'])
train_Y = pd.Series(Y)

"""
1. 모델을 초기화 합니다.
"""
lrmodel = LinearRegression() # LinearRegression 모델을 초기화 합니다.

"""
2. train_X, train_Y 데이터를 학습합니다.
"""
lrmodel.fit(train_X, train_Y) # train_X와 train_Y를 이용하여 모델을 학습 시킵니다.


# 학습한 결과를 시각화하는 코드입니다.
plt.scatter(X, Y) 
plt.plot([0, 10], [lrmodel.intercept_, 10 * lrmodel.coef_[0] + lrmodel.intercept_], c='r') 
plt.xlim(0, 10) 
plt.ylim(0, 10) 
plt.title('Training Result')
plt.savefig("test.png") 
eu.send_image("test.png")
```

![learning_result](.\learning_result.png)

3. 예측하기

> * (2. 에서)학습한 모델을 바탕으로 예측 값을 구해봅시다.
> * `LinearRegression`을 사용하여 예측을 해야한다면 아래와 같이 `predict` 함수를 사용합니다.
>
> ```python
> pred_X = lrmodel.predict(X)
> ```
>
> - `predict` 함수는 DataFrame 또는 numpy array인 `X` 데이터에 대한 예측값을 리스트로 출력합니다.

```python
'''
<목표>
lrmodel을 학습하고 train_X의 예측값을 구하여 pred_X에 저장합니다.
'''
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression

X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]
Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]

train_X = pd.DataFrame(X, columns=['X'])
train_Y = pd.Series(Y)

# 모델을 트레이닝합니다.
lrmodel = LinearRegression()
lrmodel.fit(train_X, train_Y)

"""
1. train_X에 대해서 예측합니다.
"""
pred_X = lrmodel.predict(train_X) # predict() 를 이용하여 예측합니다.
print('train_X에 대한 예측값 : \n{}\n'.format(pred_X))
print('실제값 : \n{}'.format(train_Y))

'''
train_X에 대한 예측값 : 
[6.2546398  4.18978504 3.32191889 3.92228833 5.6910886  3.79415077
 3.47870087 6.74700964 6.7906856  4.86824749]

실제값 : 
0    5.644131
1    3.758766
2    3.872333
3    4.409904
4    6.438450
5    4.028278
6    2.261060
7    7.157690
8    6.290974
9    5.196929
dtype: float64
'''
```



**다중 회귀 분석하기**

- 다중 회귀 분석(Multiple Linear Regression)은 데이터의 여러 변수(features) XX*X*를 이용해 결과 YY*Y*를 예측하는 모델입니다.
- 마케터들에게는 광고 비용에 따른 수익률을 머신러닝을 통해서 예측할 수 있다면 어떤 광고 플랫폼이 중요한 요소인지 판별할 수 있을 것입니다.

1. 데이터 전처리 

> * 아래와 같이 `FB`, `TV`, `Newspaper` 광고에 대한 비용 대비 `Sales` 데이터가 주어졌을 때, 이를 다중 회귀 분석으로 분석해봅시다.
>
> ![commercials](.\commercials.png)
>
> * 우선 데이터를 전 처리 하기 위해서 3개의 변수를 갖는 feature 데이터와 `Sales` 변수를 label 데이터로 분리하고 학습용, 평가용 데이터로 나눠봅시다.

```python
'''
<목표>
1. DataFrame으로 읽어 온 df에서 Sales 변수는 label 데이터로 Y에 저장하고 나머진 X에 저장합니다.

2. train_test_split를 사용하여 X, Y를 학습용:평가용=8:2학습용 : 평가용 = 8:2학습용:평가용=8:2 비율로 분리합니다. (random_state=42는 고정합니다.)
'''

import pandas as pd
from sklearn.model_selection import train_test_split

df = pd.read_csv("data/Advertising.csv")

print('원본 데이터 샘플 :')
print(df.head(),'\n')

# 입력 변수로 사용하지 않는 Unnamed: 0 변수 데이터를 삭제합니다
df = df.drop(columns=['Unnamed: 0'])

"""
1. Sales 변수는 label 데이터로 Y에 저장하고 나머진 X에 저장합니다.
"""
X = df.drop(columns=['Sales'])
Y = df['Sales']

"""
2. 2:8 비율로 (test_size = 0.2) X와 Y를 학습용과 평가용 데이터로 분리합니다.
"""
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42) 

# 전 처리한 데이터를 출력합니다
print('train_X : ')
print(train_X.head(),'\n')
print('train_Y : ')
print(train_Y.head(),'\n')

print('test_X : ')
print(test_X.head(),'\n')
print('test_Y : ')
print(test_Y.head())

'''
원본 데이터 샘플 :
   Unnamed: 0     FB    TV  Newspaper  Sales
0           1  230.1  37.8       69.2   22.1
1           2   44.5  39.3       45.1   10.4
2           3   17.2  45.9       69.3    9.3
3           4  151.5  41.3       58.5   18.5
4           5  180.8  10.8       58.4   12.9 

train_X : 
        FB    TV  Newspaper
79   116.0   7.7       23.1
197  177.0   9.3        6.4
38    43.1  26.7       35.1
24    62.3  12.6       18.3
122  224.0   2.4       15.6 

train_Y : 
79     11.0
197    12.8
38     10.1
24      9.7
122    11.6
Name: Sales, dtype: float64 

test_X : 
        FB    TV  Newspaper
95   163.3  31.6       52.9
15   195.4  47.7       52.9
30   292.9  28.3       43.2
158   11.7  36.9       45.2
128  220.3  49.0        3.2 

test_Y : 
95     16.9
15     22.4
30     21.4
158     7.3
128    24.7
Name: Sales, dtype: float64
'''
```

2. 학습하기

> * 다중 선형 회귀 모델의 형태는 아래 수식과 같습니다.<br>*Sales*=*β*0+*β*1*X*1+*β*2*X*2+*β*3*X*3
> * 여기서 *X*1 은 페이스북, *X*2 는 TV,  *X*3 은 신문 광고를 의미합니다.
> * 다중 선형 회귀 또한 선형 회귀 모델과 같은 방식으로 `LinearRegression`을 사용할 수 있습니다.
> * 이번 실습에서는 학습용 데이터를 다중 선형 회귀 모델을 사용하여 학습하고, 학습된 파라미터를 출력해봅시다.
> * `LinearRegression`의 `beta`와 같은 파라미터들은 아래 코드와 같이 구할 수 있습니다.
>
> ```python
> lrmodel = LinearRegression()
> lrmodel.intercept_
> lrmodel.coef_[i]
> ```
>
> * `intercept_`는 *β*0에 해당하는 값이고, `coef_[i]`는 i+1 번째 변수에 곱해지는 파라미터 값을 의미합니다.

```python
'''
<목표>
1. 다중 선형 회귀 모델 LinearRegression을 불러와 lrmodel에 초기화하고 fit을 사용하여 train_X, train_Y데이터를 학습합니다.
2. 학습된 모델 lrmodel에서 beta_0, beta_1, beta_2, beta_3에 해당하는 파라미터를 불러와 저장합니다.
'''
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# 데이터를 읽고 전 처리합니다
df = pd.read_csv("data/Advertising.csv")
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)

"""
1.  다중 선형 회귀 모델을 초기화 하고 학습합니다
"""
lrmodel = LinearRegression() # LinearRegression 모델을 초기화 합니다.
lrmodel.fit(train_X, train_Y) # train_X와 train_Y 데이터로 모델을 학습합니다.

"""
2. 학습된 파라미터 값을 불러옵니다
"""
beta_0 = lrmodel.intercept_ # y절편 (기본 판매량)
beta_1 = lrmodel.coef_[0] # 1번째 변수에 대한 계수 (페이스북)
beta_2 = lrmodel.coef_[1] # 2번째 변수에 대한 계수 (TV)
beta_3 = lrmodel.coef_[2] # 3번째 변수에 대한 계수 (신문)

print("beta_0: %f" % beta_0)
print("beta_1: %f" % beta_1)
print("beta_2: %f" % beta_2)
print("beta_3: %f" % beta_3)

'''
beta_0: 2.979067
beta_1: 0.044730
beta_2: 0.189195
beta_3: 0.002761
'''
```

3. 예측하기

> - 학습한 다중 선형 회귀모델을 바탕으로 새로운 광고 비요에 대한 Sales 값을 예측해봅시다. 

```python
'''
<목표>
1. lrmodel을 학습하고 test_X의 예측값을 구하여 pred_X에 저장합니다.
2. lrmodel을 학습하고 주어진 데이터 df1의 예측값을 구하여 pred_df1에 저장합니다.
'''
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# 데이터를 읽고 전 처리합니다
df = pd.read_csv("data/Advertising.csv")
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)


# 다중 선형 회귀 모델을 초기화 하고 학습합니다
lrmodel = LinearRegression()
lrmodel.fit(train_X, train_Y)


print('test_X : ')
print(test_X)

"""
1. test_X에 대해서 예측합니다.
"""
pred_X = lrmodel.predict(test_X) # predict()를 활용해서 예측합니다.
print('test_X에 대한 예측값 : \n{}\n'.format(pred_X))

# 새로운 데이터 df1을 정의합니다
df1 = pd.DataFrame(np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]]), columns=['FB', 'TV', 'Newspaper'])
print('df1 : ')
print(df1)

"""
2. df1에 대해서 예측합니다.
"""
pred_df1 = lrmodel.predict(df1) # predict()를 활용해서 예측합니다.
print('df1에 대한 예측값 : \n{}'.format(pred_df1))
'''
test_X : 
        FB    TV  Newspaper
95   163.3  31.6       52.9
15   195.4  47.7       52.9
30   292.9  28.3       43.2
158   11.7  36.9       45.2
128  220.3  49.0        3.2
115   75.1  35.0       52.7
69   216.8  43.9       27.2
170   50.0  11.6       18.4
174  222.4   3.4       13.1
45   175.1  22.5       31.5
66    31.5  24.6        2.2
182   56.2   5.7       29.7
165  234.5   3.4       84.8
78     5.4  29.9        9.4
186  139.5   2.1       26.6
177  170.2   7.8       35.2
56     7.3  28.1       41.4
152  197.6  23.3       14.2
82    75.3  20.3       32.5
68   237.4  27.5       11.0
124  229.5  32.3       74.2
16    67.8  36.6      114.0
148   38.0  40.3       11.9
93   250.9  36.5       72.3
65    69.0   9.3        0.9
60    53.5   2.0       21.4
84   213.5  43.0       33.8
67   139.3  14.5       10.2
125   87.2  11.8       25.9
132    8.4  27.2        2.1
9    199.8   2.6       21.2
18    69.2  20.5       18.3
55   198.9  49.4       60.0
75    16.9  43.7       89.4
150  280.7  13.9       37.0
104  238.2  34.3        5.3
135   48.3  47.0        8.5
137  273.7  28.9       59.7
164  117.2  14.7        5.4
76    27.5   1.6       20.7
test_X에 대한 예측값 : 
[16.4080242  20.88988209 21.55384318 10.60850256 22.11237326 13.10559172
 21.05719192  7.46101034 13.60634581 15.15506967  9.04831992  6.65328312
 14.34554487  8.90349333  9.68959028 12.16494386  8.73628397 16.26507258
 10.27759582 18.83109103 19.56036653 13.25103464 12.33620695 21.30695132
  7.82740305  5.80957448 20.75753231 11.98138077  9.18349576  8.5066991
 12.46646769 10.00337695 21.3876709  12.24966368 18.26661538 20.13766267
 14.05514005 20.85411186 11.0174441   4.56899622]

df1 : 
   FB  TV  Newspaper
0   0   0          0
1   1   0          0
2   0   1          0
3   0   0          1
4   1   1          1
df1에 대한 예측값 : 
[2.97906734 3.02379686 3.16826239 2.98182845 3.21575302]
'''
```



4. 회귀 알고리즘 평가 지표

- RSS

> * `Sales` 예측 모델의 성능을 평가하기 위해서 다양한 회귀 알고리즘 평가 지표를 사용하여 비교해보겠습니다.
> * 이번 실습에서는 학습용 및 평가용 데이터에 대해서 RSS를 계산해보겠습니다.
> * RSS는 아래와 같이 정의할 수 있고 간단한 수식 코드를 통하여 쉽게 구할 수 있습니다.
> * *RSS*=Σ*i*N(실제값*i*−예측값*i*)^2
> * 이때 *N*은 전체 샘플의 개수를 의미합니다.
> * `np.sum( (y_true - y_pred) ** 2 )`: RSS 값 계산하기 코드

```python
'''
<목표>
1. train_X 데이터에 대한 RSS 값을 계산하여 RSS_train에 저장합니다.
2. test_X 데이터에 대한 RSS 값을 계산하여 RSS_test에 저장합니다.
'''
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# 데이터를 읽고 전 처리합니다
df = pd.read_csv("data/Advertising.csv")
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)


# 다중 선형 회귀 모델을 초기화 하고 학습합니다
lrmodel = LinearRegression()
lrmodel.fit(train_X, train_Y)


# train_X 의 예측값을 계산합니다
pred_train = lrmodel.predict(train_X)

"""
1. train_X 의 RSS 값을 계산합니다
"""
RSS_train = np.sum( (train_Y - pred_train) ** 2) # 예측값과 실제값의 오차제곱합을 구합니다.
print('RSS_train : %f' % RSS_train)

# test_X 의 예측값을 계산합니다
pred_test = lrmodel.predict(test_X)

"""
2. test_X 의 RSS 값을 계산합니다
"""
RSS_test = np.sum( (test_Y - pred_test) ** 2) # 예측값과 실제값의 오차제곱합을 구합니다.
print('RSS_test : %f' % RSS_test)

'''
RSS_train : 432.820708
'''
```

- MSE, MAE

> * 이번 실습에서는 학습용 및 평가용 데이터에 대해서 MSE와 MAE을 계산해보겠습니다.
>
> * MSE와 MAE는 아래와 같이 정의할 수 있고 sklearn 라이브러리 함수를 통하여 쉽게 구할 수 있습니다.
>
>   ![MSE_MAE](.\MSE_MAE.PNG)
>
> * `mean_squared_error(y_true, y_pred)`: MSE 값 계산하기
>
> * `mean_absolute_error(y_true, y_pred)`: MAE 값 계산하기

```python
'''
<목표>
1. train_X 데이터에 대한 MSE, MAE 값을 계산하여 MSE_train, MAE_train에 저장합니다.
2. test_X 데이터에 대한 MSE, MAE 값을 계산하여 MSE_test, MAE_test에 저장합니다.
'''
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

# 데이터를 읽고 전 처리합니다
df = pd.read_csv("data/Advertising.csv")
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)


# 다중 선형 회귀 모델을 초기화 하고 학습합니다
lrmodel = LinearRegression()
lrmodel.fit(train_X, train_Y)


# train_X 의 예측값을 계산합니다
pred_train = lrmodel.predict(train_X)

"""
1. train_X 의 MSE, MAE 값을 계산합니다
"""
MSE_train = mean_squared_error(train_Y, pred_train) # mean_squared_error() 를 활용해서 MSE를 계산합니다.
MAE_train = mean_absolute_error(train_Y, pred_train) # mean_absolute_error() 를 활용해서 MAE를 계산합니다.
print('MSE_train : %f' % MSE_train)
print('MAE_train : %f' % MAE_train)

# test_X 의 예측값을 계산합니다
pred_test = lrmodel.predict(test_X)

"""
2. test_X 의 MSE, MAE 값을 계산합니다
"""
MSE_test = mean_squared_error(test_Y, pred_test) # mean_squared_error() 를 활용해서 MSE를 계산합니다.
MAE_test = mean_absolute_error(test_Y, pred_test) # mean_absolute_error() 를 활용해서 MAE를 계산합니다.
print('MSE_test : %f' % MSE_test)
print('MAE_test : %f' % MAE_test)

'''
MSE_train : 2.705129
MAE_train : 1.198468
MSE_test : 3.174097
MAE_test : 1.460757
'''
```

- R2(R Squared, 결정계수)

> * 이번 실습에서는 학습용 및 평가용 데이터에 대해서 R2 score를 계산해보겠습니다.
> * R2 score 는 아래와 같이 정의할 수 있고 sklearn 라이브러리 함수를 통하여 쉽게 구할 수 있습니다.
>
> ![R_squared](.\R_squared.PNG)
>
> * 이때, N은 샘플 전체의 값을 의미합니다.

```python
'''
<목표>
1. train_X 데이터에 대한 R2 값을 계산하여 R2_train에 저장합니다.
2. train_X 데이터에 대한 R2 값을 계산하여 R2_train에 저장합니다.
'''

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split

# 데이터를 읽고 전 처리합니다
df = pd.read_csv("data/Advertising.csv")
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)


# 다중 선형 회귀 모델을 초기화 하고 학습합니다
lrmodel = LinearRegression()
lrmodel.fit(train_X, train_Y)


# train_X 의 예측값을 계산합니다
pred_train = lrmodel.predict(train_X)

"""
1. train_X 의 R2 값을 계산합니다
"""
R2_train = r2_score(train_Y, pred_train) # r2_score()를 활용하여 R2값을 계산합니다.
print('R2_train : %f' % R2_train)

# test_X 의 예측값을 계산합니다
pred_test = lrmodel.predict(test_X)

"""
2. test_X 의 R2 값을 계산합니다
"""
R2_test = r2_score(test_Y, pred_test) # r2_score()를 활용하여 R2값을 계산합니다.
print('R2_test : %f' % R2_test)

'''
R2_train : 0.895701
R2_test : 0.899438
'''
```





**Q. 다음 중 회귀 알고리즘 평가 지표들에 대한 설명으로 옳지 않은 것을 고르세요.**

1. RSS: 실제값과 예측값의 단순 오차 제곱합이며, 입력값의 크기에 의존적이다.(O)
2. MSE: RSS에서 데이터 수만큼 나눈 값이며, 이상치에 민감하다.(O)
3. MAE: 실제값과 예측값의 오차의 절댓값의 평균이며, 낮을수록 모델의 성능이 높다고 평가할 수 있다.(O)
4. R2: 백분율로 표현하기 때문에 입력값의 크기에 의존적이지 않으며, 0에 가까울수록 높은 성능의 회귀 모델이라고 할 수 있다.(X)

```
RSS, MSE, MAE 모두 그 값이 낮을수록 모델의 성능이 좋다고 할 수 있습니다. 하지만 R2의 경우 그 값이 1에 가까울수록 모델의 성능이 좋다고 할 수 있습니다.
```

