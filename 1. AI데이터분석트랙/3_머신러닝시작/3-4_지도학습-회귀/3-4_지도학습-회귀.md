### 3-1. 지도학습-회귀



**Q. 아래 그래프는 회귀 분석에 대한 예시입니다. 아래 그래프와 회귀 분석에 대한 설명으로 옳지 않은 것을 고르세요.**

![regression](.\regression.png)

1. Y = beta_0 + beta_1 * X의 식을 통해 선형 회귀 분석을 하고 있다.(O)
2. 회귀 분석이란, 입력 데이터가 어떤 클래스에 속하는지 예측하기 위한 알고리즘이다.(X)
3. 각 데이터의 실제값과 모델이 예측하는 값의 차이를 최소한으로 하는 선을 찾는 과정으로 진행된다.(O)
4. 완벽한 예측은 불가능하기에 최대한 잘 근사하는 선을 찾는 것이 목표라고 할 수 있다.(O)

```
회귀 분석이란 데이터를 가장 잘 설명하는 선을 찾아 입력값에 따른 미래 결괏값을 예측하는 알고리즘입니다. 즉, 입력 데이터가 어떤 클래스에 속하는지 알아보기 위해 사용하기엔 적절치 않습니다.
```



**단순선형 회귀 분석하기**

1. 데이터 전처리 

> * 기계학습 라이브러리 [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) 을 사용하면 Loss 함수를 최솟값으로 만드는 *β*0, *β*1 을 쉽게 구할 수 있습니다.
> * 주어진 데이터를 sklearn에서 불러 올 선형 모델에 적용하기 위해서는 전 처리가 필요합니다.
> * 이번 실습에서는 sklearn에서 제공하는 `LinearRegression`을 사용하기 위한 데이터 전 처리를 수행해보겠습니다.
> * LinearRegression 모델의 입력값으로는 Pandas의 DataFrame의 feature (X) 데이터와 Series 형태의 label (Y) 데이터를 입력 받을 수 있습니다.
> * 이때, X, Y의 샘플의 개수는 같아야 합니다.

```python
'''
<목표>
1. X 데이터를 column 명이 X인 DataFrame으로 변환하고 train_X에 저장합니다.
2. 리스트 Y를 Series 형식으로 변환하여 train_Y에 저장합니다.
'''
import pandas as pd

from sklearn.linear_model import LinearRegression
    
X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]
Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]


"""
1. X의 형태를 변환하여 train_X에 저장합니다.
"""
train_X = pd.DataFrame(X, columns=['X']) # X를 column 명이 'X'인 Dataframe으로 변환합니다.

"""
2. Y의 형태를 변환하여 train_Y에 저장합니다.
"""
train_Y = pd.Series(Y) # Y를 Series로 변환합니다.

# 변환된 데이터를 출력합니다.
print('전 처리한 X 데이터: \n {}'.format(train_X))
print('전 처리한 X 데이터 shape: {}\n'.format(train_X.shape))

print('전 처리한 Y 데이터: \n {}'.format(train_Y))
print('전 처리한 Y 데이터 shape: {}'.format(train_Y.shape))
```

2. 학습하기

> * (1.에서) 전 처리한 데이터를 `LinearRegression` 모델에 입력하여 학습을 수행해봅시다.
>
> * `LinearRegression`을 사용하기 위해서는 우선 해당 모델 객체를 불러와 초기화해야 합니다. 
> * 아래 코드는 `lrmodel`에 모델 객체를 초기화 하는 것을 보여줍니다.
>
> ```python
> lrmodel = LinearRegression()
> ```
>
> * 모델 초기화를 수행했다면 전 처리된 데이터를 사용하여 학습을 수행할 수 있습니다. 아래코드와 같이 `fit` 함수에 학습에 필요한 데이터를 입력하여 학습을 수행합니다.
>
> ```python
> lrmodel.fit(train_X, train_Y)
> ```
>
> * `LinearRegression`의 *β*0, *β*1 값을 구하기 위해서는 아래 코드를 사용하여 구할 수 있습니다.
>
> ```python
> beta_0 = lrmodel.intercept_
> beta_1 = lrmodel.coef_[0]
> ```

```python
'''
<목표>
1. sklearn의 LinearRegression() 모델을 lrmodel에 초기화 합니다.
2. fit을 사용하여 train_X, train_Y 데이터를 학습합니다.
'''
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LinearRegression

import elice_utils
eu = elice_utils.EliceUtils()

X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]
Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]

train_X = pd.DataFrame(X, columns=['X'])
train_Y = pd.Series(Y)

"""
1. 모델을 초기화 합니다.
"""
lrmodel = LinearRegression() # LinearRegression 모델을 초기화 합니다.

"""
2. train_X, train_Y 데이터를 학습합니다.
"""
lrmodel.fit(train_X, train_Y) # train_X와 train_Y를 이용하여 모델을 학습 시킵니다.


# 학습한 결과를 시각화하는 코드입니다.
plt.scatter(X, Y) 
plt.plot([0, 10], [lrmodel.intercept_, 10 * lrmodel.coef_[0] + lrmodel.intercept_], c='r') 
plt.xlim(0, 10) 
plt.ylim(0, 10) 
plt.title('Training Result')
plt.savefig("test.png") 
eu.send_image("test.png")
```

![learning_result](.\learning_result.png)

3. 예측하기

> * (2. 에서)학습한 모델을 바탕으로 예측 값을 구해봅시다.
> * `LinearRegression`을 사용하여 예측을 해야한다면 아래와 같이 `predict` 함수를 사용합니다.
>
> ```python
> pred_X = lrmodel.predict(X)
> ```
>
> - `predict` 함수는 DataFrame 또는 numpy array인 `X` 데이터에 대한 예측값을 리스트로 출력합니다.

```python
'''
<목표>
lrmodel을 학습하고 train_X의 예측값을 구하여 pred_X에 저장합니다.
'''
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression

X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]
Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]

train_X = pd.DataFrame(X, columns=['X'])
train_Y = pd.Series(Y)

# 모델을 트레이닝합니다.
lrmodel = LinearRegression()
lrmodel.fit(train_X, train_Y)

"""
1. train_X에 대해서 예측합니다.
"""
pred_X = lrmodel.predict(train_X) # predict() 를 이용하여 예측합니다.
print('train_X에 대한 예측값 : \n{}\n'.format(pred_X))
print('실제값 : \n{}'.format(train_Y))

'''
train_X에 대한 예측값 : 
[6.2546398  4.18978504 3.32191889 3.92228833 5.6910886  3.79415077
 3.47870087 6.74700964 6.7906856  4.86824749]

실제값 : 
0    5.644131
1    3.758766
2    3.872333
3    4.409904
4    6.438450
5    4.028278
6    2.261060
7    7.157690
8    6.290974
9    5.196929
dtype: float64
'''
```



**다중 회귀 분석하기**

- 다중 회귀 분석(Multiple Linear Regression)은 데이터의 여러 변수(features) XX*X*를 이용해 결과 YY*Y*를 예측하는 모델입니다.
- 마케터들에게는 광고 비용에 따른 수익률을 머신러닝을 통해서 예측할 수 있다면 어떤 광고 플랫폼이 중요한 요소인지 판별할 수 있을 것입니다.

1. 데이터 전처리 

> * 아래와 같이 `FB`, `TV`, `Newspaper` 광고에 대한 비용 대비 `Sales` 데이터가 주어졌을 때, 이를 다중 회귀 분석으로 분석해봅시다.
>
> ![commercials](.\commercials.png)
>
> * 우선 데이터를 전 처리 하기 위해서 3개의 변수를 갖는 feature 데이터와 `Sales` 변수를 label 데이터로 분리하고 학습용, 평가용 데이터로 나눠봅시다.

```python
'''
<목표>
1. DataFrame으로 읽어 온 df에서 Sales 변수는 label 데이터로 Y에 저장하고 나머진 X에 저장합니다.

2. train_test_split를 사용하여 X, Y를 학습용:평가용=8:2학습용 : 평가용 = 8:2학습용:평가용=8:2 비율로 분리합니다. (random_state=42는 고정합니다.)
'''

import pandas as pd
from sklearn.model_selection import train_test_split

df = pd.read_csv("data/Advertising.csv")

print('원본 데이터 샘플 :')
print(df.head(),'\n')

# 입력 변수로 사용하지 않는 Unnamed: 0 변수 데이터를 삭제합니다
df = df.drop(columns=['Unnamed: 0'])

"""
1. Sales 변수는 label 데이터로 Y에 저장하고 나머진 X에 저장합니다.
"""
X = df.drop(columns=['Sales'])
Y = df['Sales']

"""
2. 2:8 비율로 (test_size = 0.2) X와 Y를 학습용과 평가용 데이터로 분리합니다.
"""
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42) 

# 전 처리한 데이터를 출력합니다
print('train_X : ')
print(train_X.head(),'\n')
print('train_Y : ')
print(train_Y.head(),'\n')

print('test_X : ')
print(test_X.head(),'\n')
print('test_Y : ')
print(test_Y.head())

'''
원본 데이터 샘플 :
   Unnamed: 0     FB    TV  Newspaper  Sales
0           1  230.1  37.8       69.2   22.1
1           2   44.5  39.3       45.1   10.4
2           3   17.2  45.9       69.3    9.3
3           4  151.5  41.3       58.5   18.5
4           5  180.8  10.8       58.4   12.9 

train_X : 
        FB    TV  Newspaper
79   116.0   7.7       23.1
197  177.0   9.3        6.4
38    43.1  26.7       35.1
24    62.3  12.6       18.3
122  224.0   2.4       15.6 

train_Y : 
79     11.0
197    12.8
38     10.1
24      9.7
122    11.6
Name: Sales, dtype: float64 

test_X : 
        FB    TV  Newspaper
95   163.3  31.6       52.9
15   195.4  47.7       52.9
30   292.9  28.3       43.2
158   11.7  36.9       45.2
128  220.3  49.0        3.2 

test_Y : 
95     16.9
15     22.4
30     21.4
158     7.3
128    24.7
Name: Sales, dtype: float64
'''
```

2. 학습하기

> * 다중 선형 회귀 모델의 형태는 아래 수식과 같습니다.<br>*Sales*=*β*0+*β*1*X*1+*β*2*X*2+*β*3*X*3
> * 여기서 *X*1 은 페이스북, *X*2 는 TV,  *X*3 은 신문 광고를 의미합니다.
> * 다중 선형 회귀 또한 선형 회귀 모델과 같은 방식으로 `LinearRegression`을 사용할 수 있습니다.
> * 이번 실습에서는 학습용 데이터를 다중 선형 회귀 모델을 사용하여 학습하고, 학습된 파라미터를 출력해봅시다.
> * `LinearRegression`의 `beta`와 같은 파라미터들은 아래 코드와 같이 구할 수 있습니다.
>
> ```python
> lrmodel = LinearRegression()
> lrmodel.intercept_
> lrmodel.coef_[i]
> ```
>
> * `intercept_`는 *β*0에 해당하는 값이고, `coef_[i]`는 i+1 번째 변수에 곱해지는 파라미터 값을 의미합니다.

```python
'''
<목표>
1. 다중 선형 회귀 모델 LinearRegression을 불러와 lrmodel에 초기화하고 fit을 사용하여 train_X, train_Y데이터를 학습합니다.
2. 학습된 모델 lrmodel에서 beta_0, beta_1, beta_2, beta_3에 해당하는 파라미터를 불러와 저장합니다.
'''
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# 데이터를 읽고 전 처리합니다
df = pd.read_csv("data/Advertising.csv")
df = df.drop(columns=['Unnamed: 0'])

X = df.drop(columns=['Sales'])
Y = df['Sales']

train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)

"""
1.  다중 선형 회귀 모델을 초기화 하고 학습합니다
"""
lrmodel = LinearRegression() # LinearRegression 모델을 초기화 합니다.
lrmodel.fit(train_X, train_Y) # train_X와 train_Y 데이터로 모델을 학습합니다.

"""
2. 학습된 파라미터 값을 불러옵니다
"""
beta_0 = lrmodel.intercept_ # y절편 (기본 판매량)
beta_1 = lrmodel.coef_[0] # 1번째 변수에 대한 계수 (페이스북)
beta_2 = lrmodel.coef_[1] # 2번째 변수에 대한 계수 (TV)
beta_3 = lrmodel.coef_[2] # 3번째 변수에 대한 계수 (신문)

print("beta_0: %f" % beta_0)
print("beta_1: %f" % beta_1)
print("beta_2: %f" % beta_2)
print("beta_3: %f" % beta_3)

'''
beta_0: 2.979067
beta_1: 0.044730
beta_2: 0.189195
beta_3: 0.002761
'''
```

3. 예측하기

> * 

