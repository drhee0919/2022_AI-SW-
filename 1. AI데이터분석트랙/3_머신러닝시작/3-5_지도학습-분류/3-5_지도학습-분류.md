### 3-5. 지도학습-분류



**Q. 다음 중 회귀(Regression)와 분류(Classification)에 대한 설명으로 옳지 않은 것을 고르세요. **

1. 회귀는 회귀 식을 통해 주어진 데이터에 대한 결과 값을 예측한다.(O)
2. 분류는 주어진 입력이 어느 클래스에 속하는지 판별하는 것이다.O)
3. 선형 회귀의 식은 별다른 변형 없이 분류에 바로 적용 가능하다.(X)
4. 다양한 분류 알고리즘이 존재하며, 예측 목표와 데이터 유형에 따라 적합한 모델을 적용한다.(O)

```
선형 회귀 식은 -∞ ~ +∞의 결괏값을 가질 수 있습니다. 따라서 일반적인 회귀 알고리즘은 분류 문제에 그대로 사용할 수 없습니다. 그렇기에 선형 회귀 식을 분류에 사용하기 위해선 적절한 변형이 필요합니다.
```



**분류 알고리즘**

- 분류 문제에 다양한 머신러닝 모델을 사용하여 해결 

> - 트리 구조 기반: 의사결정나무, 랜덤 포레스트...
> - 확률 모델 기반: 나이브 베이즈 분류기... 
> - 결정 경계 기반: 선형 분류기, 로지스틱 회기 분류기, SVM... 
> - 신경망: 퍼셉트론, 딥러닝 모델...



**의사결정나무**

- 의사결정나무는 간단하면서도 다른 기법들과 함께 쓰이면서(ex/ 앙상블 기법) 고성능을 낼 수 있음. 
- 실습을 통해 sklearn을 이용한 의사결정모델을 구현해 보겠습니다.  
- 분류 문제 해결을 위해 대표적으로  Iris 데이터를 사용합니다. 
- Iris 데이터는 아래와 같이 **꽃받침 길이, 꽃받침 넓이, 꽃잎 길이, 꽃잎 넓이** 네 가지 변수와 **세 종류의 붓꽃 클래스**로 구성되어 있습니다.

![iris](.\iris.png)

- **꽃받침 길이, 꽃받침 넓이, 꽃잎 길이, 꽃잎 넓이** 네 가지 변수가 주어졌을 때, 어떠한 붓꽃 종류인지 예측하는 분류 모델을 구현해보도록 하겠습니다.

1. 전처리하기 

> * 4개의 변수를 갖는 feature 데이터와 클래스 변수를 label 데이터로 분리하고 학습용, 평가용 데이터로 나눠봅시다.

```python
'''
<목표>
load_iris로 읽어 온 데이터 X에서 Y 를 바탕으로 train_test_split를 사용하여 
학습용 : 평가용 = 8:2 비율로 분리합니다. (random_state=42는 고정합니다.)
'''

import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# sklearn에 저장된 데이터를 불러 옵니다.
X, Y = load_iris(return_X_y = True)

# DataFrame으로 변환
df = pd.DataFrame(X, columns=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'])
df['클래스'] = Y

X = df.drop(columns=['클래스'])
Y = df['클래스']

"""
1. 학습용 평가용 데이터로 분리합니다
"""
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)

# 원본 데이터 출력
print('원본 데이터 : \n',df.head(),'\n')

# 전 처리한 데이터 5개만 출력합니다
print('train_X : ')
print(train_X[:5],'\n')
print('train_Y : ')
print(train_Y[:5],'\n')

print('test_X : ')
print(test_X[:5],'\n')
print('test_Y : ')
print(test_Y[:5])

'''
원본 데이터 : 
    꽃받침 길이  꽃받침 넓이  꽃잎 길이  꽃잎 넓이  클래스
0     5.1     3.5    1.4    0.2    0
1     4.9     3.0    1.4    0.2    0
2     4.7     3.2    1.3    0.2    0
3     4.6     3.1    1.5    0.2    0
4     5.0     3.6    1.4    0.2    0 

train_X : 
    꽃받침 길이  꽃받침 넓이  꽃잎 길이  꽃잎 넓이
22     4.6     3.6    1.0    0.2
15     5.7     4.4    1.5    0.4
65     6.7     3.1    4.4    1.4
11     4.8     3.4    1.6    0.2
42     4.4     3.2    1.3    0.2 

train_Y : 
22    0
15    0
65    1
11    0
42    0
Name: 클래스, dtype: int64 

test_X : 
     꽃받침 길이  꽃받침 넓이  꽃잎 길이  꽃잎 넓이
73      6.1     2.8    4.7    1.2
18      5.7     3.8    1.7    0.3
118     7.7     2.6    6.9    2.3
78      6.0     2.9    4.5    1.5
76      6.8     2.8    4.8    1.4 

test_Y : 
73     1
18     0
118    2
78     1
76     1
Name: 클래스, dtype: int64
'''
```

2. 학습하기 

> * 전 처리한 데이터를 바탕으로 의사결정나무 모델을 학습하겠습니다
> * 각 노드에서 불순도를 최소로 하는 의사결정나무 모델을 구현하기 위해서는 sklearn의 `DecisionTreeClassifier`을 사용합니다. 이 모델을 학습하고 모델의 구조를 살펴봅시다.
> * `DecisionTreeClassifier`을 사용하기 위해서는 우선 해당 모델 객체를 불러와 초기화해야 합니다. 아래 코드는 `DTmodel`에 모델 객체를 초기화 하는 것을 보여줍니다.
>
> ```python
> DTmodel = DecisionTreeClassifier()
> ```
>
> * 모델 초기화를 수행했다면 전 처리된 데이터를 사용하여 학습을 수행할 수 있습니다. 아래 코드와 같이 `fit` 함수에 학습에 필요한 데이터를 입력하여 학습을 수행합니다.
>
>   ※회귀분석때 linear regression을 떠올려보자
>
> ```python
> DTmodel.fit(train_X, train_Y)
> ```
>
> ※TIPS
>
> ```python
> DTmodel = DecisionTreeClassifier(max_depth=2)
> ```
>
> * 위 코드처럼 초기화를 수행할 때 `max_depth`를 설정하여 의사결정나무의 최대 깊이를 조절할 수 있습니다. (2 이외의 다른 값을 넣어서 확인해보세요.)
> * 너무 깊이를 깊게 설정하면 문제에 대한 과적합이 발생할 수 있다. 

```python
'''
<목표>
1. sklearn의 DecisionTreeClassifier() 모델을 DTmodel에 초기화 합니다.
2. fit을 사용하여 train_X, train_Y 데이터를 학습합니다.
'''
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import tree

from elice_utils import EliceUtils
elice_utils = EliceUtils()

# sklearn에 저장된 데이터를 불러 옵니다.
X, Y = load_iris(return_X_y = True)

# DataFrame으로 변환
df = pd.DataFrame(X, columns=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'])
df['클래스'] = Y

X = df.drop(columns=['클래스'])

Y = df['클래스']
    
# 학습용 평가용 데이터로 분리합니다
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)


"""
1. DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다.
"""
DTmodel = DecisionTreeClassifier()
DTmodel.fit(train_X, train_Y)


# 학습한 결과를 출력합니다
plt.rc('font', family='NanumBarunGothic')
fig = plt.figure(figsize=(25,20))
_ = tree.plot_tree(DTmodel, 
                   feature_names=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'],  
                   class_names=['setosa', 'versicolor', 'virginica'],
                   filled=True)

fig.savefig("decision_tree.png")
elice_utils.send_image("decision_tree.png")
```

![decision_tree_classifier](.\decision_tree_classifier.png)

3. 예측하기 

> * 학습한 모델을 바탕으로 새로운 데이터에 대해서 예측해보겠습니다.
> * `test_X` 데이터에 따른 예측값을 구해봅시다.
> * `DecisionTreeClassifier`을 사용하여 예측을 해야 한다면 아래와 같이 `predict` 함수를 사용합니다.
>
> ```python
> pred_X = DTmodel.predict(test_X)
> ```

```python
'''
<목표>
DTmodel을 학습하고 test_X의 예측값을 구하여 pred_X에 저장합니다.
'''
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

# sklearn에 저장된 데이터를 불러 옵니다.
X, Y = load_iris(return_X_y = True)

# DataFrame으로 변환
df = pd.DataFrame(X, columns=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'])
df['클래스'] = Y

X = df.drop(columns=['클래스'])

Y = df['클래스']
    
# 학습용 평가용 데이터로 분리합니다
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)


# DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다
DTmodel = DecisionTreeClassifier()
DTmodel.fit(train_X, train_Y)


"""
1. test_X에 대해서 예측합니다.
"""
pred_X = DTmodel.predict(test_X)
print('test_X에 대한 예측값 : \n{}'.format(pred_X))


'''
test_X에 대한 예측값 : 
[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]
'''
```



**간단한 의사결정나무 만들기 **

> * 항공 지연 데이터를 기반으로 간단한 의사결정나무를 구현해 보겠습니다.
> * 항공 지연 데이터는 아래와 같습니다.
>
> ![flight_delay](.\flight_delay.png)
>
> * 풍속에 따른 지연 여부를 알아내기 위하여 의사결정나무인 `binary_tree`의 기준값(`threshold`)을 변경해가며 완벽하게 지연 여부를 분리할 수 있는 모델을 만들어봅시다.
>
> ![binary_tree](.\binary_tree.png)

```python
'''
<목표>
binary_tree 함수는 입력하는 threshold 풍속을 기준으로 지연 여부를 예측한 결과를 DataFrame 형태로 출력합니다. data의 지연 여부와 예상 지연 여부가 같은 값이 나오도록 의사결정나무의 결과물을 data_pred에 저장하세요.
threshold 에 원하는 값을 넣어서 결과를 확인합니다. (ex) 1, 2, 3.5, …)
'''
import pandas as pd

# 풍속을 threshold 값에 따라 분리하는 의사결정나무 모델 함수
def binary_tree(data, threshold):
    
    yes = []
    no = []
    
    # data로부터 풍속 값마다 비교를 하기 위한 반복문
    for wind in data['풍속']:
    
        # threshold 값과 비교하여 분리합니다.
        if wind > threshold:
            yes.append(wind)
        else:
            no.append(wind)
    
    # 예측한 결과를 DataFrame 형태로 저장합니다.
    data_yes = pd.DataFrame({'풍속': yes, '예상 지연 여부': ['Yes']*len(yes)})
    data_no = pd.DataFrame({'풍속': no, '예상 지연 여부': ['No']*len(no)})
    
    return data_no.append(data_yes,ignore_index=True)

# 풍속에 따른 항공 지연 여부 데이터
Wind = [1, 1.5, 2.5, 5, 5.5, 6.5]
Delay  = ['No', 'No', 'No', 'Yes', 'Yes', 'Yes']

# 위 데이터를 DataFrame 형태로 저장합니다.
data = pd.DataFrame({'풍속': Wind, '지연 여부': Delay})
print(data,'\n')

"""
1. binary_tree 모델을 사용하여 항공 지연 여부를 예측합니다.
"""
data_pred = binary_tree(data, threshold = 2.5) #기준점 2.5로 지정 
print(data_pred,'\n')

'''
    풍속 지연 여부
0  1.0    No
1  1.5    No
2  2.5    No
3  5.0   Yes
4  5.5   Yes
5  6.5   Yes 

    풍속 예상 지연 여부
0  1.0       No
1  1.5       No
2  2.5       No
3  5.0      Yes
4  5.5      Yes
5  6.5      Yes 
'''
```



**정확도 계산하기**

> * 항공 지연 데이터로 구현한 binary tree 모델의 결과를 바탕으로 분류 성능에 간단하면서도 중요한 정확도를 계산하여 모델의 성능을 판별해보겠습니다.
> * 이번 실습에서는 학습용 데이터와 평가용 데이터의 정확도를 계산하고 그 성능을 비교해보겠습니다.
> * 정확도 계산을 위한 사이킷런 함수/라이브러리
>
> ```python
> # train_X 데이터에 대한 정확도(accuracy) 값을 계산합니다.
> DTmodel.score(train_X, train_Y)
> ```

```python
'''
<목표>
1. score를 사용하여 train_X에 대한 정확도를 계산하여 acc_train에 저장해봅시다.
2. score를 사용하여 test_X에 대한 정확도를 계산하여 acc_test에 저장해봅시다.
'''

"""
<데이터 정보>
- load_breast_cancer 유방암 유무 판별 데이터를 불러오는 함수
- X(Feature 데이터) : 30개의 환자 데이터
- Y(Label 데이터) : 0 음성(악성), 1 양성(정상
"""
"""
※TIPS
accuracy_score(Y_true, Y_pred)을 이용하여 정확도를 구할 수 있습니다. Y_true,Y_pred는 각각 실제값과 예측값을 의미합니다.
"""

import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

# sklearn에 저장된 데이터를 불러 옵니다.
X, Y = load_breast_cancer(return_X_y = True)
X = np.array(X)
Y = np.array(Y)

# 학습용 평가용 데이터로 분리합니다
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)

# 분리된 데이터 정보를 출력합니다
print('학습용 샘플 개수: ',len(train_Y))
print('클래스 0인 학습용 샘플 개수: ',len(train_Y)-sum(train_Y))
print('클래스 1인 학습용 샘플 개수: ',sum(train_Y),'\n')

print('평가용 샘플 개수: ',len(test_Y))
print('클래스 0인 평가용 샘플 개수: ',len(test_Y)-sum(test_Y))
print('클래스 1인 평가용 샘플 개수: ',sum(test_Y),'\n')

# DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다
DTmodel = DecisionTreeClassifier()
DTmodel.fit(train_X, train_Y)


# 예측한 값을 저장합니다
y_pred_train = DTmodel.predict(train_X)
y_pred_test = DTmodel.predict(test_X)

# 혼동 행렬을 계산합니다
cm_train = confusion_matrix(train_Y, y_pred_train)
cm_test = confusion_matrix(test_Y, y_pred_test)
print('train_X Confusion Matrix : \n {}'.format(cm_train))
print('test_X Confusion Matrix : \n {}'.format(cm_test))

"""
1. 정확도를 계산합니다.
"""
acc_train = DTmodel.score(train_X, train_Y) # score() 함수를 활용하여 정확도를 계산합니다.
acc_test = DTmodel.score(test_X, test_Y)

# 정확도를 출력합니다.
print('train_X Accuracy: %f' % (acc_train))
print('test_X Accuracy: %f' % (acc_test))

'''
학습용 샘플 개수:  455
클래스 0인 학습용 샘플 개수:  169
클래스 1인 학습용 샘플 개수:  286 

평가용 샘플 개수:  114
클래스 0인 평가용 샘플 개수:  43
클래스 1인 평가용 샘플 개수:  71 

train_X Confusion Matrix : 
 [[169   0]
 [  0 286]]
test_X Confusion Matrix : 
 [[39  4]
 [ 3 68]]
train_X Accuracy: 1.000000
test_X Accuracy: 0.938596
'''
```



**정밀도(Precision), 재현율(Recall) 계산하기**

> - 결과를 바탕으로 분류 지표 중 정밀도와 재현율을 계산하여 모델의 성능을 판별해보겠습니다.
> - 학습용 데이터와 평가용 데이터의 정밀도와 재현율을 계산하고 그 성능을 비교해보겠습니다.
> - 정밀도와 재현율 계산을 위한 사이킷런 함수/라이브러리
>
> ```python
> # 학습용 데이터에 대한 정밀도(precision) 값을 계산합니다.
> precision_score(train_Y, y_pred_train)
> 
> #학습용 데이터에 대한 재현율(recall) 값을 계산합니다.
> recall_score(train_Y, y_pred_train)
> ```

```python
'''
<목표>
1. precision_score를 사용하여 학습용, 평가용 데이터에 대한 정밀도를 계산하여 precision_train, precision_test에 저장해봅시다.

2. recall_score를 사용하여학습용, 평가용 데이터에 대한 재현율을 계산하여 recall_train, recall_test에 저장해봅시다.
'''
"""
<데이터 정보>
- load_breast_cancer 유방암 유무 판별 데이터를 불러오는 함수
- X(Feature 데이터) : 30개의 환자 데이터
- Y(Label 데이터) : 0 음성(악성), 1 양성(정상)
"""

import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

# sklearn에 저장된 데이터를 불러 옵니다.
X, Y = load_breast_cancer(return_X_y = True)
X = np.array(X)
Y = np.array(Y)

# 학습용 평가용 데이터로 분리합니다
train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)

# DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다
DTmodel = DecisionTreeClassifier()
DTmodel.fit(train_X, train_Y)


# 예측한 값을 저장합니다
y_pred_train = DTmodel.predict(train_X)
y_pred_test = DTmodel.predict(test_X)

# 혼동 행렬을 계산합니다
cm_train = confusion_matrix(train_Y, y_pred_train)
cm_test = confusion_matrix(test_Y, y_pred_test)
print('train_X Confusion Matrix : \n {}'.format(cm_train))
print('test_X Confusion Matrix : \n {}'.format(cm_test),'\n')

"""
1. 정밀도를 계산합니다.
"""
precision_train = precision_score(train_Y, y_pred_train) # precision_score()를 활용하여 정밀도를 계산합니다.
precision_test = precision_score(test_Y, y_pred_test)

# 정밀도를 출력합니다.
print('train_X Precision: %f' % (precision_train))
print('test_X Precision: %f' % (precision_test),'\n')

"""
2. 재현율을 계산합니다.
"""
recall_train = recall_score(train_Y, y_pred_train) # recall_score()를 활용하여 재현율을 계산합니다.
recall_test = recall_score(test_Y, y_pred_test)

# 재현율을 출력합니다.
print('train_X Recall: %f' % (recall_train))
print('test_X Recall: %f' % (recall_test))

'''
train_X Confusion Matrix : 
 [[169   0]
 [  0 286]]
test_X Confusion Matrix : 
 [[39  4]
 [ 4 67]] 

train_X Precision: 1.000000
test_X Precision: 0.943662 

train_X Recall: 1.000000
test_X Recall: 0.943662
'''
```

